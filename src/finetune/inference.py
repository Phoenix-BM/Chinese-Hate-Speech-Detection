import json
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import os
import re
os.environ["CUDA_VISIBLE_DEVICES"] = "3"
model_path = "/new_data/NLP/CCL2025-Chinese-Hate-Speech-Detection-main/qwen-hate-finetune-1/qwentotest_1e-4new/checkpoint-9500"

tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_path, device_map="auto", trust_remote_code=True)
model.eval()

test_data= []

with open(f"/new_data/NLP/CCL2025-Chinese-Hate-Speech-Detection-main/data/raw_data/test1.json", "r", encoding="utf-8") as f:
    test_data = json.load(f)
    
def build_prompt(text):
    basic_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªå†…å®¹å®¡æŸ¥ä¸“å®¶,è¯·ä½ åˆ†ææˆ‘çš„å¥å­å¹¶ä¸”ä»ä¸­æå–å‡ºä¸€ä¸ªæˆ–è€…å¤šä¸ªå››å…ƒç»„ã€‚\n"
        "è¯·ä»ä¸‹é¢çš„æ–‡æœ¬æŠ½å–ä¸€ä¸ªæˆ–å¤šä¸ªå››å…ƒç»„,æ¯ä¸€ä¸ªå››å…ƒç»„è¾“å‡ºæ ¼å¼ä¸º:\n"
        "è¯„è®ºå¯¹è±¡|å¯¹è±¡è§‚ç‚¹|æ˜¯å¦ä»‡æ¨|ä»‡æ¨ç¾¤ä½“ã€‚\n"
        "è¯„è®ºå¯¹è±¡å¯ä»¥ä¸º'NULL',å¯¹è±¡è§‚ç‚¹å°½é‡ç®€æ´,ä»‡æ¨ç¾¤ä½“åªåŒ…æ‹¬(LGBTQã€Regionã€Sexismã€Racismã€othersã€non-hate),"
        "åŒä¸€å››å…ƒç»„å¯èƒ½æ¶‰åŠå¤šä¸ªä»‡æ¨ç¾¤ä½“,æ˜¯å¦ä»‡æ¨æ ‡ç­¾ä¸º(hateã€non-hate),å¤šä¸ªå››å…ƒç»„ä¹‹é—´ç”¨[SEP]åˆ†éš”,æœ€åä¸€ä¸ªå››å…ƒç»„åé¢åŠ [END]ã€‚\n"
        # "ä»‡æ¨æ ·æœ¬è¾“å…¥:è°å–œæ¬¢å°é»‘å•Š,é»‘ä¸æ‹‰å‡ çš„çœ‹ä¸€çœ¼éƒ½å«Œè„,ä¹Ÿå°±æŸäº›è¿æ±½è½¦æ’æ°”å£éƒ½ä¸æ”¾è¿‡çš„ç”· äººä¼šå–œæ¬¢é»‘å¦ ä»‡æ¨æ ·æœ¬è¾“å‡º:å°é»‘|é»‘ä¸æ‹‰å‡ çš„çœ‹ä¸€çœ¼éƒ½å«Œè„|Racism|hate [SEP] æŸäº›è¿æ±½è½¦æ’æ°”å£éƒ½ä¸æ”¾è¿‡ çš„ç”·äºº|å–œæ¬¢é»‘å¦|Sexism, Racism|hate [END]  éä»‡æ¨æ ·æœ¬è¾“å…¥:ç”±åŒæ€§ä¼´ä¾£æŠšå…»é•¿å¤§çš„å­©å­,åœ¨å­¦æ ¡è¡¨ç°æ¯”å¼‚æ€§ä¼´ä¾£æŠšå…»çš„å­©å­æ›´å¥½,å¹¶ä¸”æ¯” å¼‚æ€§ä¼´ä¾£çš„å­©å­é«˜ä¸­æ¯•ä¸šç‡é«˜å‡º4.8%ã€‚ éä»‡æ¨æ ·æœ¬è¾“å‡º:ç”±åŒæ€§ä¼´ä¾£æŠšå…»é•¿å¤§çš„å­©å­|åœ¨å­¦æ ¡è¡¨ç°æ¯”å¼‚æ€§ä¼´ä¾£æŠšå…»çš„å­©å­æ›´å¥½|nonhate|non-hate [END]  \n"
        "æå–å‡ºå¥å­ä¸­åŒ…å«çš„æ‰€æœ‰å››å…ƒç»„ï¼š\n"
        f"{text}\n"
    )
    return basic_prompt

def build_am_prompt(example):
    # åŸºæœ¬çš„ prompt æ ¼å¼
    # slang=[]
    # for v in slang_dic:
    #     if v["Term"] in example:
    #         slang.append(v)
    
    # slang_text=""
    # for v in slang:
    #     slang_text+=f"\"{v['Term']}\"çš„æ„æ€æ˜¯:\"{v['Definition']}\"ï¼Œ\"{v['Term']}\"çš„ä»‡æ¨ç±»åˆ«å½’å±äº\"{v['Groups']}\"\n"
    print(example)
    basic_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªå†…å®¹å®¡æŸ¥ä¸“å®¶,è¯·ä½ åˆ†ææˆ‘çš„å¥å­å¹¶ä¸”ä»ä¸­æå–å‡ºä¸€ä¸ªæˆ–è€…å¤šä¸ªäºŒå…ƒç»„ã€‚\n"
        "è¯·ä»ä¸‹é¢çš„æ–‡æœ¬æŠ½å–ä¸€ä¸ªæˆ–å¤šä¸ªäºŒå…ƒç»„,æ¯ä¸€ä¸ªäºŒå…ƒç»„è¾“å‡ºæ ¼å¼ä¸º:\n"
        "è¯„è®ºå¯¹è±¡|å¯¹è±¡è§‚ç‚¹ã€‚\n"
        "è¯„è®ºå¯¹è±¡å¯ä»¥ä¸º'NULL',å¯¹è±¡è§‚ç‚¹å°½é‡ç®€æ´, è¯„è®ºå¯¹è±¡å’Œå¯¹è±¡è§‚ç‚¹éƒ½è¦å‡†ç¡®åœ°æ¥è‡ªè¿™å¥è¯"
        "åŒä¸€å››å…ƒç»„å¯èƒ½æ¶‰åŠå¤šä¸ªè¯„è®ºå¯¹è±¡|å¯¹è±¡è§‚ç‚¹,å¤šä¸ªäºŒå…ƒç»„ä¹‹é—´ç”¨[SEP]åˆ†éš”,æœ€åä¸€ä¸ªäºŒå…ƒç»„åé¢åŠ [END]ã€‚\n"
        # "æ ·æœ¬è¾“å…¥:è°å–œæ¬¢å°é»‘å•Š,é»‘ä¸æ‹‰å‡ çš„çœ‹ä¸€çœ¼éƒ½å«Œè„,ä¹Ÿå°±æŸäº›è¿æ±½è½¦æ’æ°”å£éƒ½ä¸æ”¾è¿‡çš„ç”· äººä¼šå–œæ¬¢é»‘å¦\n"
        # "æ ·æœ¬è¾“å‡º:å°é»‘ | é»‘ä¸æ‹‰å‡ çš„çœ‹ä¸€çœ¼éƒ½å«Œè„ [SEP] æŸäº›è¿æ±½è½¦æ’æ°”å£éƒ½ä¸æ”¾è¿‡çš„ç”·äºº | å–œæ¬¢é»‘å¦ [END]\n"
        # "æ ·æœ¬è¾“å…¥:ç”±åŒæ€§ä¼´ä¾£æŠšå…»é•¿å¤§çš„å­©å­,åœ¨å­¦æ ¡è¡¨ç°æ¯”å¼‚æ€§ä¼´ä¾£æŠšå…»çš„å­©å­æ›´å¥½,å¹¶ä¸”æ¯” å¼‚æ€§ä¼´ä¾£çš„å­©å­é«˜ä¸­æ¯•ä¸šç‡é«˜å‡º4.8%\n"
        # "æ ·æœ¬è¾“å‡º:ç”±åŒæ€§ä¼´ä¾£æŠšå…»é•¿å¤§çš„å­©å­|åœ¨å­¦æ ¡è¡¨ç°æ¯”å¼‚æ€§ä¼´ä¾£æŠšå…»çš„å­©å­æ›´å¥½|nonhate|non-hate [END]  \n"
        # "è¯·ä½¿ç”¨ COT æ€ç»´é“¾è¿›è¡Œä»¥ä¸‹çš„æ€è€ƒæ­¥éª¤ï¼Œæœ€åç›´æ¥è¾“å‡ºç»“æœ"
        # "ã€æ­¥éª¤1ã€‘è¯†åˆ«è¯„è®ºä¸­æåˆ°çš„å¯¹è±¡ï¼ˆTargetï¼‰ï¼›"
        # "ã€æ­¥éª¤2ã€‘è¯†åˆ«è¯¥å¯¹è±¡æ‰€å…³è”çš„è¯„è®º/è§‚ç‚¹ï¼ˆArgumentï¼‰ï¼›"
        # "ã€æ­¥éª¤3ã€‘åˆ¤æ–­è¯¥å¯¹è±¡-è§‚ç‚¹ç»„åˆæ˜¯å¦æ„æˆä»‡æ¨â¾”è®ºï¼ˆHateful: hate æˆ– non-hateï¼‰ï¼›"
        # "ã€æ­¥éª¤4ã€‘å¦‚æœæ˜¯ä»‡æ¨ï¼Œåˆ¤æ–­å…¶å±äºå“ªä¸ªç¾¤ä½“ç±»åˆ«ï¼ˆGroup: Region, Racism, LGBTQ,Sexism, Othersï¼‰ï¼›"
        # "ã€æ­¥éª¤5ã€‘å°†æ¯ä¸ªç»“æœè¾“å‡ºä¸ºå››å…ƒç»„æ ¼å¼ï¼šTarget | Argument | Group | Hateful"
        # "å¤šä¸ªå››å…ƒç»„ä¹‹é—´â½¤ [SEP] åˆ†éš”ï¼Œæœ€åâ¼€ä¸ªåŠ ä¸Š [END]"
        # "å¥å­ä¸­å‡ºç°çš„ä¿šè¯­å¯¹ä»‡æ¨åˆ†æèµ·åˆ°å…³é”®ä½œç”¨,ä»¥ä¸‹å¯èƒ½ä¼šç”¨åˆ°çš„ä¿šè¯­è¯å…¸ï¼Œæ³¨æ„æ˜¯å¯èƒ½ï¼Œæ˜¯å¦æ„æˆä»‡æ¨è¿˜éœ€è¦å…·ä½“æƒ…å†µå…·ä½“åˆ†æ\n"
        # f"{slang_text}"
        "æå–å‡ºå¥å­ä¸­åŒ…å«çš„æ‰€æœ‰äºŒå…ƒç»„ï¼š\n"
        f"{example}\n"
    )
    return basic_prompt

def generate_prediction(text):
    prompt = build_prompt(text)
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    with torch.no_grad():
        outputs = model.generate(**inputs, max_new_tokens=128)
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response,prompt

def classify_result(data):
    others_hate = []
    emoji_sentences = []
    abbr_sentences = []
    slang_sentences = []

    # è¡¨æƒ…å­—ç¬¦æ­£åˆ™
    emoji_pattern = re.compile("[\U00010000-\U0010ffff]", flags=re.UNICODE)

    # ç¼©å†™æ­£åˆ™ï¼šåˆ¤æ–­æ˜¯å¦åŒ…å«è¿ç»­çš„è‹±æ–‡å•è¯æˆ–ç¼©å†™
    abbr_pattern = re.compile(r'\b[a-zA-Z]{2,}\b')

    slang_keywords = ["ç‰›å¤´æ€ª", "é»˜ğŸ¶", "é»˜å­å­", "å†²", "ä¸Šæ¡", "å†²é”™", "jrs", "å¯„", "zz", "yyds", "nt", "fw", "ä¹", "å“­äº†", "æ‰“å·¥äºº"]

    for item in data:
        content = item.get("content", "")
        output = item.get("ground_truth", "")

        if "others | hate" in output:
            others_hate.append(item)

        if emoji_pattern.search(content):
            emoji_sentences.append(item)

        if abbr_pattern.search(content):
            abbr_sentences.append(item)

        if any(slang in content for slang in slang_keywords):
            slang_sentences.append(item)
    
    return others_hate, emoji_sentences, abbr_sentences, slang_sentences

def save_to_file(data, filename):
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

from tqdm import tqdm

idd=0
results = []
for item in tqdm(test_data, desc="Running inference"):
    result,prompt = generate_prediction(item["content"])
    # result=item["output"]
    prediction = result.split(prompt, 1)[-1].strip()
    if idd<15:
        print(prediction)
    idd+=1
    results.append({
        "id": item["id"],
        "content": item["content"],
        "prediction": prediction,
        # "ground_truth": item["output"]
    })

# åˆ†ç±»
# others_hate, emoji_sentences, abbr_sentences, slang_sentences=classify_result(results)

# ä¿å­˜ç»“æœ
with open("/new_data/NLP/CCL2025-Chinese-Hate-Speech-Detection-main/data/qwen-new-1e-4.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)
# save_to_file(others_hate, "/new_data/NLP/CCL2025-Chinese-Hate-Speech-Detection-main/data/classify/others_hate.json")
# save_to_file(emoji_sentences, "/new_data/NLP/CCL2025-Chinese-Hate-Speech-Detection-main/data/classify/emoji_sentences.json")
# save_to_file(abbr_sentences, "/new_data/NLP/CCL2025-Chinese-Hate-Speech-Detection-main/data/classify/abbr_sentences.json")
# save_to_file(slang_sentences, "/new_data/NLP/CCL2025-Chinese-Hate-Speech-Detection-main/data/classify/slang_sentences.json")
